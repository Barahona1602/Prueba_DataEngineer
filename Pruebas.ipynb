{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJWmIyzJUi9Z"
      },
      "source": [
        "# **PRUEBA TÉCNICA SOLVEX - PABLO JOSUÉ BARAHONA LUNCEY**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwpkH_plUgPJ"
      },
      "source": [
        "## Ejercicio 1:\n",
        "Utiliza Pandas y el conjunto de datos público de COVID-19 proporcionado por la\n",
        "Universidad de Johns Hopkins para realizar las siguientes tareas:\n",
        "- Descarga los datos de COVID-19 en formato CSV o JSON desde la URL\n",
        "pública.\n",
        "- Carga los datos en un DataFrame de Pandas.\n",
        "- Calcula el promedio de casos confirmados por día en un país específico.\n",
        "- Encuentra los 10 países con la tasa de mortalidad más alta (número de\n",
        "muertes / número de casos confirmados) hasta la fecha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wXglcLsPUbu4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los archivos CSV\n",
        "deaths_csv = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
        "confirmed_csv = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
        "deaths = pd.read_csv(deaths_csv)\n",
        "confirmed = pd.read_csv(confirmed_csv)\n",
        "\n",
        "# Transformar data\n",
        "deaths = deaths.drop(columns=['Province/State', 'Lat', 'Long'])\n",
        "confirmed = confirmed.drop(columns=['Province/State', 'Lat', 'Long'])\n",
        "\n",
        "# Agrupar los datos por 'Country/Region' y sumar los valores\n",
        "deaths = deaths.groupby('Country/Region').sum()\n",
        "confirmed = confirmed.groupby('Country/Region').sum()\n",
        "\n",
        "# Cálculo de promedio de casos\n",
        "def avg_country(country):\n",
        "    if country in confirmed.index:\n",
        "        country_data = confirmed.loc[country]\n",
        "        cases_avg = round(country_data.diff().mean(), 3)\n",
        "        print(f\"{country}: {cases_avg}\")\n",
        "    else:\n",
        "        print(f\"{country} no se encuentra en los datos de casos confirmados.\")\n",
        "\n",
        "# Top 10 mortalidad\n",
        "# Suma de muertes y casos confirmados\n",
        "death_total = deaths.sum(axis=1)\n",
        "cases_total = confirmed.sum(axis=1)\n",
        "\n",
        "# Calculo de tasa de mortalidad\n",
        "mortality_rate = round((death_total / cases_total) * 100, 2)\n",
        "\n",
        "# Ordenar y seleccionar los 10 países con mayor tasa de mortalidad\n",
        "mortality_rate_sort = mortality_rate.sort_values(ascending=False)\n",
        "top10_countries = mortality_rate_sort.head(10)\n",
        "mortality_top10 = pd.DataFrame({\n",
        "    'Country': top10_countries.index,\n",
        "    'Mortality Rate (%)': top10_countries.values\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9TZEenBUsRj",
        "outputId": "efc8a47b-86ab-4573-a1e3-755d819f2965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promedio de casos confirmados por día en: \n",
            "Guatemala: 1084.279\n",
            "Italy: 22419.886\n",
            "US: 90895.535\n",
            "-------------------------------------------\n",
            "Top 10 países con mayor tasa de mortalidad: \n",
            "        Country  Mortality Rate (%)\n",
            "0  Korea, North              600.00\n",
            "1    MS Zaandam               22.20\n",
            "2         Yemen               19.23\n",
            "3         Sudan                7.41\n",
            "4          Peru                6.83\n",
            "5        Mexico                6.11\n",
            "6         Syria                5.86\n",
            "7         Egypt                5.16\n",
            "8       Somalia                5.03\n",
            "9       Ecuador                4.53\n"
          ]
        }
      ],
      "source": [
        "# Promedio de casos por día por país específico\n",
        "print(\"Promedio de casos confirmados por día en: \")\n",
        "avg_country(\"Guatemala\")\n",
        "avg_country(\"Italy\")\n",
        "avg_country(\"US\")\n",
        "\n",
        "print(\"-------------------------------------------\")\n",
        "\n",
        "# Top 10 países con mayor tasa de mortalidad\n",
        "print(\"Top 10 países con mayor tasa de mortalidad: \")\n",
        "print(mortality_top10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VCLiAFJSdzl"
      },
      "source": [
        "## Ejercicio 2:\n",
        "Utiliza Apache Spark y un conjunto de datos público de vuelos, como el conjunto\n",
        "de datos de vuelos de 2015 proporcionado por la Oficina de Estadísticas de\n",
        "Transporte de EE. UU., para realizar las siguientes tareas:\n",
        "- Descarga los datos de vuelos en formato CSV desde la URL pública.\n",
        "- Carga los datos en un DataFrame de Spark.\n",
        "- Calcula la cantidad promedio de retrasos en la llegada de vuelos en un\n",
        "aeropuerto específico.\n",
        "- Encuentra las 10 rutas de vuelo más populares (pares de aeropuertos) en\n",
        "términos de la cantidad de vuelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUNzJ5-VNPB",
        "outputId": "7d825912-3fd1-4d4e-caa1-09f433d839bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3_VVqWAlNYF8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, least, greatest\n",
        "\n",
        "# Inicializar una sesión de Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Flight Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Cargar los datos desde el archivo CSV\n",
        "file_path = \"T_ONTIME_REPORTING_01.csv\"\n",
        "df_flights = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "def delay_airport(specific_airport):\n",
        "    # Filtrar los vuelos que llegan a este aeropuerto\n",
        "    df_arrivals = df_flights.filter(col(\"DEST\") == specific_airport)\n",
        "    # Calcular el promedio de retrasos en la llegada\n",
        "    average_arrival_delay = df_arrivals.agg(avg(col(\"ARR_DELAY_NEW\")).alias(\"AverageArrivalDelay\")).collect()[0][\"AverageArrivalDelay\"]\n",
        "    print(f\"Promedio de retrasos en la llegada en {specific_airport}: {average_arrival_delay:.2f} minutos\")\n",
        "\n",
        "# 10 rutas de vuelo más populares por pares de aeropuertos\n",
        "def top10_airports():\n",
        "    # Crear columnas para el par de aeropuertos en orden alfabético\n",
        "    df_routes = df_flights.withColumn(\"Origen\", least(col(\"ORIGIN\"), col(\"DEST\"))) \\\n",
        "                          .withColumn(\"Destino\", greatest(col(\"ORIGIN\"), col(\"DEST\")))\n",
        "    \n",
        "    # Contar los vuelos por cada par único de aeropuertos\n",
        "    df_route_counts = df_routes.groupBy(\"Origen\", \"Destino\").agg(count(\"*\").alias(\"Vuelos\"))\n",
        "    df_route_counts = df_route_counts.withColumn(\"Vuelos\", col(\"Vuelos\") / 2)\n",
        "    \n",
        "    # Ordenar las rutas por la cantidad de vuelos en orden descendente y obtener las 10 más populares\n",
        "    top_10_routes = df_route_counts.orderBy(col(\"Vuelos\").desc()).limit(10)\n",
        "    \n",
        "    # Mostrar las 10 rutas de vuelo más populares\n",
        "    print(\"Top 10 rutas de vuelo más populares (pares de aeropuertos):\")\n",
        "    top_10_routes.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYDq5ejnSSMv",
        "outputId": "02a7b4f9-dd4f-4ee8-e189-9a52397c5b93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restraso en aeropuertos específicos: \n",
            "Promedio de retrasos en la llegada en JFK: 16.35 minutos\n",
            "Promedio de retrasos en la llegada en ABI: 15.41 minutos\n",
            "------------------------------------------\n",
            "Top 10 rutas de vuelo más populares (pares de aeropuertos):\n",
            "+------+-------+------+\n",
            "|Origen|Destino|Vuelos|\n",
            "+------+-------+------+\n",
            "|   JFK|    LAX|1144.0|\n",
            "|   LAX|    SFO|1105.5|\n",
            "|   LAS|    LAX| 941.5|\n",
            "|   LGA|    ORD| 854.0|\n",
            "|   HNL|    OGG| 820.0|\n",
            "|   JFK|    SFO| 736.0|\n",
            "|   ATL|    LGA| 718.0|\n",
            "|   LAS|    SFO| 710.5|\n",
            "|   ATL|    MCO| 707.0|\n",
            "|   DFW|    ORD| 677.0|\n",
            "+------+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Restraso en aeropuertos específicos: \")\n",
        "delay_airport(\"JFK\")\n",
        "delay_airport(\"ABI\")\n",
        "\n",
        "print(\"------------------------------------------\")\n",
        "\n",
        "top10_airports()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URgehpFfSWXb"
      },
      "source": [
        "## Ejercicio 3:\n",
        "Supongamos que tienes dos conjuntos de datos: uno en Pandas y otro en Spark. El\n",
        "conjunto de datos de Pandas es una tabla llamada \"datos_peliculas\" con\n",
        "información sobre películas:\n",
        "```\n",
        "ID,Título,Año\n",
        "1,Película1,2020\n",
        "2,Película2,2019\n",
        "3,Película3,2021\n",
        "4,Película4,2018\n",
        "```\n",
        "El conjunto de datos de Spark es un DataFrame llamado \"criticas\" con información\n",
        "sobre las críticas de películas:\n",
        "```\n",
        "PeliculaID,Criticoo,Puntuacion\n",
        "1,Criticoo1,4.5\n",
        "2,Criticoo2,3.8\n",
        "3,Criticoo1,4.2\n",
        "4,Criticoo3,4.7\n",
        "```\n",
        "Combina estos dos conjuntos de datos para obtener una tabla que muestre el\n",
        "título de la película, el año de lanzamiento y la puntuación promedio de las\n",
        "críticas. Asegúrate de utilizar tanto Pandas como Spark en el proceso de\n",
        "integración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEh-fFwhKVuw",
        "outputId": "80fc3360-c377-4cdb-faae-2378ebceaf7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----+-----------+\n",
            "|Título   |Año |PromedioPts|\n",
            "+---------+----+-----------+\n",
            "|Película4|2018|4.7        |\n",
            "|Película3|2021|4.2        |\n",
            "|Película2|2019|3.8        |\n",
            "|Película1|2020|4.5        |\n",
            "+---------+----+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg\n",
        "\n",
        "# Crear una sesión de Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Movies and Ratings Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Crear DataFrame de Pandas\n",
        "datos_peliculas = pd.DataFrame({\n",
        "    'ID': [1, 2, 3, 4],\n",
        "    'Título': ['Película1', 'Película2', 'Película3', 'Película4'],\n",
        "    'Año': [2020, 2019, 2021, 2018]\n",
        "})\n",
        "\n",
        "# Convertir el DataFrame de Pandas a un DataFrame de Spark\n",
        "movies_spark_df = spark.createDataFrame(datos_peliculas)\n",
        "\n",
        "# Crear DataFrame de Spark con las críticas\n",
        "criticas = spark.createDataFrame([\n",
        "    (1, 'Criticoo1', 4.5),\n",
        "    (2, 'Criticoo2', 3.8),\n",
        "    (3, 'Criticoo1', 4.2),\n",
        "    (4, 'Criticoo3', 4.7)\n",
        "], ['PeliculaID', 'Critico', 'Puntuacion'])\n",
        "\n",
        "# Renombrar columnas en el DataFrame de películas para facilitar la combinación\n",
        "movies_spark_df = movies_spark_df.withColumnRenamed('ID', 'PeliculaID')\n",
        "\n",
        "# Unir los DataFrames de películas y críticas\n",
        "combined_df = movies_spark_df.join(criticas, on='PeliculaID', how='left')\n",
        "\n",
        "# Calcular la puntuación promedio de las críticas por película\n",
        "result_df = combined_df.groupBy('Título', 'Año').agg(avg(col('Puntuacion')).alias('PromedioPts'))\n",
        "\n",
        "# Mostrar el resultado\n",
        "result_df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnOjN9YKU6Uh"
      },
      "source": [
        "## Ejercicio Web Scraping:\n",
        "Supongamos que deseas obtener el precio actual del Bitcoin (BTC) de un sitio\n",
        "web de criptomonedas. La información que necesitas se encuentra en la página\n",
        "de https://coinmarketcap.com/currencies/bitcoin/.\n",
        "Tu tarea es escribir un script en Python que realice lo siguiente:\n",
        "- Realiza una solicitud GET a la URL https://coinmarketcap.com/currencies/bitcoin/ utilizando la biblioteca `requests`.\n",
        "- Analiza el contenido de la página web para extraer el precio actual del Bitcoin.\n",
        "- Imprime el precio en la consola"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn77Eh3LU85H",
        "outputId": "64eff003-5bd8-4e57-ca7f-34324cb36575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El precio actual del Bitcoin es: $58,247.03\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL de la página de CoinMarketCap\n",
        "url = 'https://coinmarketcap.com/currencies/bitcoin/'\n",
        "\n",
        "# Realiza una solicitud GET para obtener el contenido de la página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica si la solicitud fue exitosa (código de respuesta 200)\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    try:\n",
        "        price_element = soup.find('span', class_='sc-65e7f566-0 clvjgF base-text')\n",
        "        if price_element:\n",
        "            # Extrae el precio del elemento y almacénalo en una variable\n",
        "            price = price_element.text\n",
        "            # Imprime el precio en la consola\n",
        "            print(f'El precio actual del Bitcoin es: {price}')\n",
        "        else:\n",
        "            print('No se pudo encontrar el elemento del precio.')\n",
        "    except Exception as e:\n",
        "        print(f'Ocurrió un error al extraer el precio: {e}')\n",
        "else:\n",
        "    print(f'Error al hacer la solicitud. Código de respuesta: {response.status_code}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h2M9EiIVEiZ"
      },
      "source": [
        "## Teoría:\n",
        "\n",
        "¿Cuál de las siguientes plataformas de Microsoft es una solución de análisis de big data en la nube?\n",
        "- Azure Synapse Analytics\n",
        "\n",
        "En el contexto de Azure Data Factory, ¿cuál de las siguientes actividades se utiliza para transformar y limpiar datos en un flujo de trabajo?\n",
        "- Data Flow\n",
        "\n",
        "¿Cuál de las siguientes opciones es una característica clave de Apache Spark que permite procesar datos en memoria para un rendimiento más rápido?\n",
        "- Resilient Distributed Dataset (RDD)\n",
        "\n",
        "En el contexto de Pandas, ¿cuál de las siguientes operaciones se utiliza para eliminar filas duplicadas de un DataFrame?\n",
        "- df.drop_duplicates()\n",
        "\n",
        "¿Qué lenguaje de programación se utiliza comúnmente en Azure Databricks para el procesamiento de datos y análisis?\n",
        "- Scala"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
